{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于CycleGAN的竹叶字体生成\n",
    "\n",
    "\n",
    "> 本案例运行需要较大内存，建议在Ascend/GPU上运行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型介绍\n",
    "\n",
    "### 模型简介\n",
    "\n",
    "CycleGAN(Cycle Generative Adversarial Network) 即循环对抗生成网络，来自论文 [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593) 。该模型实现了一种在没有配对示例的情况下学习将图像从源域 X 转换到目标域 Y 的方法。\n",
    "\n",
    "该模型一个重要应用领域是域迁移(Domain Adaptation)，可以通俗地理解为图像风格迁移。其实在 CycleGAN 之前，就已经有了域迁移模型，比如 Pix2Pix ，但是 Pix2Pix 要求训练数据必须是成对的，而现实生活中，要找到两个域（画风）中成对出现的图片是相当困难的，因此 CycleGAN 诞生了，它只需要两种域的数据，而不需要他们有严格对应关系，是一种新的无监督的图像迁移网络。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型结构\n",
    "\n",
    "CycleGAN 网络本质上是由两个镜像对称的 GAN 网络组成，其结构如下图所示（图片来源于原论文）：\n",
    "\n",
    "![CycleGAN](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0rc2/tutorials/application/source_zh_cn/generative/images/CycleGAN.png)\n",
    "\n",
    "为了方便理解，这里以苹果和橘子为例介绍。上图中 $X$ 可以理解为苹果，$Y$ 为橘子；$G$ 为将苹果生成橘子风格的生成器，$F$ 为将橘子生成的苹果风格的生成器，$D_{X}$ 和 $D_{Y}$ 为其相应判别器，具体生成器和判别器的结构可见下文代码。模型最终能够输出两个模型的权重，分别将两种图像的风格进行彼此迁移，生成新的图像。\n",
    "\n",
    "该模型一个很重要的部分就是损失函数，在所有损失里面循环一致损失(Cycle Consistency Loss)是最重要的。循环损失的计算过程如下图所示（图片来源于原论文）：\n",
    "\n",
    "![Cycle Consistency Loss](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0rc2/tutorials/application/source_zh_cn/generative/images/CycleGAN_1.png)\n",
    "\n",
    "图中苹果图片 $x$ 经过生成器 $G$ 得到伪橘子 $\\hat{Y}$，然后将伪橘子 $\\hat{Y}$ 结果送进生成器 $F$ 又产生苹果风格的结果 $\\hat{x}$，最后将生成的苹果风格结果 $\\hat{x}$ 与原苹果图片 $x$ 一起计算出循环一致损失，反之亦然。循环损失捕捉了这样的直觉，即如果我们从一个域转换到另一个域，然后再转换回来，我们应该到达我们开始的地方。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "\n",
    "本案例为CycleGAN在字体设计方面的衍生使用，使用的数据集分为两组，分别是内容图片，置于TrainA文件夹内；风格图片，置于TrainB文件夹内。通过训练可将TrainB文件夹内图片风格迁移至TrainA内容图片上。TrainA、TrainB文件夹内图片分辨率大小、格式应统一，推荐使用256px，72dpi或512px，72dpi大小的.jpg或.png格式图片。\n",
    "\n",
    "本案例中，TrainA放置楷体字体png带白底照片，可通过字库解包的python代码获得。TrainB文件夹内放置手动收集与处理的竹叶png带白底图片，通过机器学习的训练，将TrainB文件夹中竹叶的风格迁移至TrainA的楷体字体上，生成风格独特的竹叶字体。\n",
    "\n",
    "通过OTF或TTF字体库解包，获得需要进行转换的字体图片集。通过裁剪边缘、二值化、重置图片大小等图片处理方法，将字体图片中的文字尽量居中，且在上下左右留出适当的距离。本案例提供楷体文字png图片数据集300张，放置于TrainA文件夹内，数据集概览如下：\n",
    "\n",
    "![TrainA-dataset](https://mindspore-courses.obs.cn-north-4.myhuaweicloud.com/deep%20learning/AI%2BX/image/20240815-184509.PNG)\n",
    "\n",
    "通过手动搜集与处理的300张竹叶png图片数据，同样将其进行二值化与重置图片大小，放置于TrainB文件夹内。数据集概览如下：\n",
    "\n",
    "![TrainB-dataset](https://mindspore-courses.obs.cn-north-4.myhuaweicloud.com/deep%20learning/AI%2BX/image/20240815-184406.PNG)\n",
    "\n",
    "将TrainA与TrainB文件夹一同放置于根目录下的dataset文件夹内，完成数据集的预处理。\n",
    "\n",
    "### 数据集下载\n",
    "\n",
    "使用 `download` 接口下载数据集，并将下载后的数据集自动解压到当前目录下。数据下载之前需要使用 `pip install download` 安装 `download` 包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\n",
      "Requirement already satisfied: download in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (0.3.5)\n",
      "Requirement already satisfied: six in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from download) (1.16.0)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from download) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from download) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->download) (2024.2.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: no_proxy='a.test.com,127.0.0.1,2.2.2.2'\n",
      "Downloading data from https://mindspore-courses.obs.cn-north-4.myhuaweicloud.com/deep%20learning/AI%2BX/data/Bamboo_leaf_font_data.zip (14.8 MB)\n",
      "\n",
      "file_sizes: 100%|██████████████████████████| 15.6M/15.6M [00:00<00:00, 31.6MB/s]\n",
      "Extracting zip file...\n",
      "Successfully downloaded / unzipped to .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env no_proxy='a.test.com,127.0.0.1,2.2.2.2'\n",
    "from download import download\n",
    "\n",
    "url = \"https://mindspore-courses.obs.cn-north-4.myhuaweicloud.com/deep%20learning/AI%2BX/data/Bamboo_leaf_font_data.zip\"\n",
    "\n",
    "download(url, \".\", kind=\"zip\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定参数\n",
    "设置案例所需参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"get args.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import ast\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Cycle GAN')\n",
    "\n",
    "# basic parameters\n",
    "parser.add_argument('--platform', type=str, default='Ascend', help='support GPU and Ascend, and CPU')\n",
    "parser.add_argument('--device_id', type=int, default=0, help='device id, default is 0.')\n",
    "parser.add_argument('--device_num', type=int, default=1, help='device num, default is 1.')\n",
    "parser.add_argument('--is_save_on_master', type=int, default=1,\n",
    "                    help='Save ckpt on master or all rank, 1 for master, 0 for all ranks. Default: 1')\n",
    "parser.add_argument('--rank', type=int, default=0, help='Local rank of distributed. Default: 0')\n",
    "parser.add_argument('--group_size', type=int, default=1, help='World size of device. Default: 1')\n",
    "parser.add_argument('--model', type=str, default='ResNet', choices=('DepthResNet', 'ResNet', 'UNet'), \\\n",
    "                    help='generator model')\n",
    "parser.add_argument('--init_type', type=str, default='normal', choices=('normal', 'xavier'), \\\n",
    "                    help='network initialization, default is normal.')\n",
    "parser.add_argument('--init_gain', type=float, default=0.02, \\\n",
    "                    help='scaling factor for normal, xavier and orthogonal, default is 0.02.')\n",
    "parser.add_argument('--image_size', type=int, default=256, help='input image_size, default is 256.')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='batch_size, default is 1.')\n",
    "parser.add_argument('--pool_size', type=int, default=50, \\\n",
    "                     help='the size of image buffer that stores previously generated images')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='Adam beta1, default is 0.5.')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default is 0.0002.')\n",
    "parser.add_argument('--lr_policy', type=str, default='linear', choices=('linear', 'constant'), \\\n",
    "                    help='learning rate policy, default is linear')\n",
    "parser.add_argument('--max_epoch', type=int, default=200, help='epoch size for training, default is 200.')\n",
    "parser.add_argument('--n_epochs', type=int, default=100, \\\n",
    "                    help='number of epochs with the initial learning rate, default is 100')\n",
    "\n",
    "# model parameters\n",
    "parser.add_argument('--in_planes', type=int, default=3, help='input channels, default is 3.')\n",
    "parser.add_argument('--ngf', type=int, default=64, help='generator model filter numbers, default is 64.')\n",
    "parser.add_argument('--gl_num', type=int, default=9, help='generator model residual block numbers, default is 9.')\n",
    "parser.add_argument('--ndf', type=int, default=64, help='discriminator model filter numbers, default is 64.')\n",
    "parser.add_argument('--dl_num', type=int, default=3, \\\n",
    "                    help='discriminator model residual block numbers, default is 3.')\n",
    "parser.add_argument('--slope', type=float, default=0.2, help='leakyrelu slope, default is 0.2.')\n",
    "parser.add_argument('--norm_mode', type=str, default='batch', choices=('batch', 'instance'), \\\n",
    "                    help='norm mode, default is batch.')\n",
    "parser.add_argument('--lambda_A', type=float, default=10.0, \\\n",
    "                    help='weight for cycle loss (A -> B -> A), default is 10.')\n",
    "parser.add_argument('--lambda_B', type=float, default=10.0, \\\n",
    "                    help='weight for cycle loss (B -> A -> B), default is 10.')\n",
    "parser.add_argument('--lambda_idt', type=float, default=0.5, \\\n",
    "                    help='use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the '\n",
    "                         'weight of the identity mapping loss. For example, if the weight of the identity loss '\n",
    "                         'should be 10 times smaller than the weight of the reconstruction loss,'\n",
    "                         'please set lambda_identity = 0.1, default is 0.5.')\n",
    "parser.add_argument('--gan_mode', type=str, default='lsgan', choices=('lsgan', 'vanilla'), \\\n",
    "                    help='the type of GAN loss, default is lsgan.')\n",
    "parser.add_argument('--pad_mode', type=str, default='CONSTANT', choices=('CONSTANT', 'REFLECT', 'SYMMETRIC'), \\\n",
    "                    help='the type of Pad, default is CONSTANT.')\n",
    "\n",
    "# additional parameters\n",
    "parser.add_argument('--dataroot', default='./data/dataset/', \\\n",
    "                    help='path of images (should have subfolders trainA, trainB, testA, testB, etc).')\n",
    "parser.add_argument('--data_dir', default='testA', choices=('testA', 'testB'), \\\n",
    "                    help='the translation direction of CycleGAN.')\n",
    "parser.add_argument('--outputs_dir', type=str, default='./outputs', \\\n",
    "                    help='models are saved here, default is ./outputs.')\n",
    "parser.add_argument('--load_ckpt', type=ast.literal_eval, default=False, \\\n",
    "                    help='whether load pretrained ckpt')\n",
    "parser.add_argument('--G_A_ckpt', type=str, default='./outputs/ckpt/G_A_200.ckpt', \\\n",
    "                    help='checkpoint file path of G_A.')\n",
    "parser.add_argument('--G_B_ckpt', type=str, default='./outputs/ckpt/G_B_200.ckpt', \\\n",
    "                    help='checkpoint file path of G_B.')\n",
    "parser.add_argument('--D_A_ckpt', type=str, default='./outputs/ckpt/D_A_200.ckpt', \\\n",
    "                    help='checkpoint file path of D_A.')\n",
    "parser.add_argument('--D_B_ckpt', type=str, default='./outputs/ckpt/D_B_200.ckpt', \\\n",
    "                    help='checkpoint file path of D_B.')\n",
    "parser.add_argument('--save_checkpoint_epochs', type=int, default=10, \\\n",
    "                    help='Save checkpoint epochs, default is 10.')\n",
    "parser.add_argument('--print_iter', type=int, default=100, help='log print iter, default is 100.')\n",
    "parser.add_argument('--need_profiler', type=ast.literal_eval, default=False, \\\n",
    "                    help='whether need profiler, default is False.')\n",
    "parser.add_argument('--save_graphs', type=ast.literal_eval, default=False, \\\n",
    "                    help='whether save graphs, default is False.')\n",
    "parser.add_argument('--save_imgs', type=ast.literal_eval, default=True, \\\n",
    "                    help='whether save imgs when epoch end')\n",
    "parser.add_argument('--save_img_nums', type=int, default=3, \\\n",
    "                    help='Save img nums when epoch end')\n",
    "parser.add_argument('--use_random', type=ast.literal_eval, default=True, \\\n",
    "                    help='whether use random when training, default is True.')\n",
    "parser.add_argument('--need_dropout', type=ast.literal_eval, default=False, \\\n",
    "                    help='whether need dropout, default is True.')\n",
    "parser.add_argument('--max_dataset_size', type=int, default=None, \\\n",
    "                    help='max images pre epoch, default is None.')\n",
    "\n",
    "# export parameters\n",
    "parser.add_argument(\"--export_batch_size\", type=int, default=1, \\\n",
    "                    help=\"batch size\")\n",
    "parser.add_argument(\"--export_file_name\", type=str, default=\"CycleGAN\", \\\n",
    "                    help=\"output file name.\")\n",
    "parser.add_argument(\"--export_file_format\", type=str, choices=[\"AIR\", \"ONNX\", \"MINDIR\"], \\\n",
    "                    default='MINDIR', help=\"file format\")\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_args(args=[]) # run .ipynb use this\n",
    "\n",
    "\n",
    "def get_args(phase):\n",
    "    \"\"\"Define the common options that are used in both training and test.\"\"\"\n",
    "    if args.platform == \"Ascend\":\n",
    "        args.pad_mode = \"CONSTANT\"\n",
    "\n",
    "    if phase != \"train\" and (args.G_A_ckpt is None or args.G_B_ckpt is None):\n",
    "        raise ValueError('Must set G_A_ckpt and G_B_ckpt in predict phase!')\n",
    "\n",
    "    if args.batch_size == 1:\n",
    "        args.norm_mode = \"instance\"\n",
    "\n",
    "    if args.dataroot is None:\n",
    "        raise ValueError('Must set dataroot!')\n",
    "\n",
    "    if args.max_dataset_size is None:\n",
    "        args.max_dataset_size = float(\"inf\")\n",
    "\n",
    "    args.n_epochs = min(args.max_epoch, args.n_epochs)\n",
    "    args.n_epochs_decay = args.max_epoch - args.n_epochs\n",
    "    args.phase = phase\n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集加载\n",
    "\n",
    "使用 MindSpore 的 `GeneratorDataset` 接口读取和解析数据集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Dataset distributed sampler.\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DistributedSampler:\n",
    "    \"\"\"Distributed sampler.\"\"\"\n",
    "    def __init__(self, dataset_size, num_replicas=None, rank=None, shuffle=True):\n",
    "        if num_replicas is None:\n",
    "            print(\"***********Setting world_size to 1 since it is not passed in ******************\")\n",
    "            num_replicas = 1\n",
    "        if rank is None:\n",
    "            print(\"***********Setting rank to 0 since it is not passed in ******************\")\n",
    "            rank = 0\n",
    "        self.dataset_size = dataset_size\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "        self.epoch = 0\n",
    "        self.num_samples = int(math.ceil(dataset_size * 1.0 / self.num_replicas))\n",
    "        self.total_size = self.num_samples * self.num_replicas\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        # deterministically shuffle based on epoch\n",
    "        if self.shuffle:\n",
    "            indices = np.random.RandomState(seed=self.epoch).permutation(self.dataset_size)\n",
    "            # np.array type. number from 0 to len(dataset_size)-1, used as index of dataset\n",
    "            indices = indices.tolist()\n",
    "            self.epoch += 1\n",
    "            # change to list type\n",
    "        else:\n",
    "            indices = list(range(self.dataset_size))\n",
    "\n",
    "        # add extra samples to make it evenly divisible\n",
    "        indices += indices[:(self.total_size - len(indices))]\n",
    "        assert len(indices) == self.total_size\n",
    "\n",
    "        # subsample\n",
    "        indices = indices[self.rank:self.total_size:self.num_replicas]\n",
    "        assert len(indices) == self.num_samples\n",
    "\n",
    "        return iter(indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "\"\"\"Cycle GAN dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mindspore.dataset as de\n",
    "import mindspore.dataset.vision as C\n",
    "\n",
    "IMG_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.tif', '.tiff']\n",
    "\n",
    "def is_image_file(filename):\n",
    "    \"\"\"Judge whether it is a picture.\"\"\"\n",
    "    return any(filename.lower().endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "\n",
    "def make_dataset(dir_path, max_dataset_size=float(\"inf\")):\n",
    "    \"\"\"Return image list in dir.\"\"\"\n",
    "    images = []\n",
    "    assert os.path.isdir(dir_path), '%s is not a valid directory' % dir_path\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(dir_path)):\n",
    "        for fname in fnames:\n",
    "            if is_image_file(fname):\n",
    "                path = os.path.join(root, fname)\n",
    "                images.append(path)\n",
    "    return images[:min(max_dataset_size, len(images))]\n",
    "\n",
    "\n",
    "class UnalignedDataset:\n",
    "    \"\"\"\n",
    "    This dataset class can load unaligned/unpaired datasets.\n",
    "    It requires two directories to host training images from domain A '/path/to/data/trainA'\n",
    "    and from domain B '/path/to/data/trainB' respectively.\n",
    "    You can train the model with the dataset flag '--dataroot /path/to/data'.\n",
    "    Similarly, you need to prepare two directories:\n",
    "    '/path/to/data/testA' and '/path/to/data/testB' during test time.\n",
    "    Returns:\n",
    "        Two domain image path list.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataroot, phase, max_dataset_size=float(\"inf\"), use_random=True):\n",
    "        self.dir_A = os.path.join(dataroot, phase + 'A')\n",
    "        self.dir_B = os.path.join(dataroot, phase + 'B')\n",
    "\n",
    "        self.A_paths = sorted(make_dataset(self.dir_A, max_dataset_size))   # load images from '/path/to/data/trainA'\n",
    "        self.B_paths = sorted(make_dataset(self.dir_B, max_dataset_size))    # load images from '/path/to/data/trainB'\n",
    "        self.A_size = len(self.A_paths)  # get the size of dataset A\n",
    "        self.B_size = len(self.B_paths)  # get the size of dataset B\n",
    "        self.use_random = use_random\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return a data point and its metadata information.\n",
    "\n",
    "        Parameters:\n",
    "            index (int)      -- a random integer for data indexing\n",
    "\n",
    "        Returns a dictionary that contains A, B, A_paths and B_paths\n",
    "            A (tensor)       -- an image in the input domain\n",
    "            B (tensor)       -- its corresponding image in the target domain\n",
    "            A_paths (str)    -- image paths\n",
    "            B_paths (str)    -- image paths\n",
    "        \"\"\"\n",
    "        index_B = index % self.B_size\n",
    "        if index % max(self.A_size, self.B_size) == 0 and self.use_random:\n",
    "            random.shuffle(self.A_paths)\n",
    "            index_B = random.randint(0, self.B_size - 1)\n",
    "        A_path = self.A_paths[index % self.A_size]\n",
    "        B_path = self.B_paths[index_B]\n",
    "        A_img = np.array(Image.open(A_path).convert('RGB'))\n",
    "        B_img = np.array(Image.open(B_path).convert('RGB'))\n",
    "\n",
    "        return A_img, B_img\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of images in the dataset.\n",
    "        \"\"\"\n",
    "        # return max(self.A_size, self.B_size)\n",
    "        return self.A_size\n",
    "\n",
    "\n",
    "class ImageFolderDataset:\n",
    "    \"\"\"\n",
    "    This dataset class can load images from image folder.\n",
    "    Args:\n",
    "        dataroot (str): Images root directory.\n",
    "        max_dataset_size (int): Maximum number of return image paths.\n",
    "    Returns:\n",
    "        Image path list.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataroot, max_dataset_size=float(\"inf\")):\n",
    "        self.dataroot = dataroot\n",
    "        self.paths = sorted(make_dataset(dataroot, max_dataset_size))\n",
    "        self.size = len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.paths[index % self.size]\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "\n",
    "        return img, os.path.split(img_path)[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of images in the dataset.\n",
    "        As we have two datasets with potentially different number of images,\n",
    "        we take a maximum of\n",
    "        \"\"\"\n",
    "        return self.size\n",
    "\n",
    "\n",
    "def create_dataset(args):\n",
    "    \"\"\"\n",
    "    Create dataset\n",
    "    This dataset class can load images for train or test.\n",
    "    Args:\n",
    "        dataroot (str): Images root directory.\n",
    "    Returns:\n",
    "        RGB Image list.\n",
    "    \"\"\"\n",
    "    dataroot = args.dataroot\n",
    "    phase = args.phase\n",
    "    batch_size = args.batch_size\n",
    "    device_num = args.device_num\n",
    "    rank = args.rank\n",
    "    shuffle = args.use_random\n",
    "    max_dataset_size = args.max_dataset_size\n",
    "    cores = multiprocessing.cpu_count()\n",
    "    num_parallel_workers = 1\n",
    "    # num_parallel_workers = min(8, int(cores / device_num))\n",
    "    image_size = args.image_size\n",
    "    mean = [0.5 * 255] * 3\n",
    "    std = [0.5 * 255] * 3\n",
    "    if phase == \"train\":\n",
    "        dataset = UnalignedDataset(dataroot, phase, max_dataset_size=max_dataset_size, use_random=args.use_random)\n",
    "        distributed_sampler = DistributedSampler(len(dataset), device_num, rank, shuffle=shuffle)\n",
    "        ds = de.GeneratorDataset(dataset, column_names=[\"image_A\", \"image_B\"],\n",
    "                                 sampler=distributed_sampler, num_parallel_workers=num_parallel_workers)\n",
    "        if args.use_random:\n",
    "            trans = [\n",
    "                # C.RandomResizedCrop(image_size, scale=(0.5, 1.0), ratio=(0.75, 1.333)),\n",
    "                # C.RandomHorizontalFlip(prob=0.5),\n",
    "                C.RandomResizedCrop(image_size, scale=(1.0, 1.0), ratio=(1.0, 1.0)),\n",
    "                C.RandomHorizontalFlip(prob=0),\n",
    "                C.Normalize(mean=mean, std=std),\n",
    "                C.HWC2CHW()\n",
    "            ]\n",
    "        else:\n",
    "            trans = [\n",
    "                C.Resize((image_size, image_size)),\n",
    "                C.Normalize(mean=mean, std=std),\n",
    "                C.HWC2CHW()\n",
    "            ]\n",
    "        ds = ds.map(operations=trans, input_columns=[\"image_A\"], num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.map(operations=trans, input_columns=[\"image_B\"], num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        datadir = os.path.join(dataroot, args.data_dir)\n",
    "        dataset = ImageFolderDataset(datadir, max_dataset_size=max_dataset_size)\n",
    "        ds = de.GeneratorDataset(dataset, column_names=[\"image\", \"image_name\"],\n",
    "                                 num_parallel_workers=num_parallel_workers)\n",
    "        trans = [\n",
    "            C.Resize((image_size, image_size)),\n",
    "            C.Normalize(mean=mean, std=std),\n",
    "            C.HWC2CHW()\n",
    "        ]\n",
    "        ds = ds.map(operations=trans, input_columns=[\"image\"], num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(1, drop_remainder=True)\n",
    "    args.dataset_size = len(dataset)\n",
    "    return ds\n",
    "\n",
    "\n",
    "import mindspore as ms\n",
    "from mindspore.communication import init, get_rank, get_group_size\n",
    "\n",
    "args = get_args(\"train\")\n",
    "args.batch_size = 1\n",
    "args.dataroot = './data/dataset/'\n",
    "\n",
    "if args.device_num > 1:\n",
    "    ms.set_context(mode=ms.GRAPH_MODE, device_target=args.platform, save_graphs=args.save_graphs)\n",
    "    init()\n",
    "    ms.reset_auto_parallel_context()\n",
    "    ms.set_auto_parallel_context(parallel_mode=ms.ParallelMode.DATA_PARALLEL, gradients_mean=True)\n",
    "    args.rank = get_rank()\n",
    "    args.group_size = get_group_size()\n",
    "else:\n",
    "    ms.set_context(mode=ms.GRAPH_MODE, device_target=args.platform,\n",
    "                   save_graphs=args.save_graphs, device_id=args.device_id)\n",
    "    args.rank = 0\n",
    "    args.device_num = 1\n",
    "\n",
    "if args.platform == \"GPU\":\n",
    "    ms.set_context(enable_graph_kernel=True)\n",
    "if args.need_profiler:\n",
    "    from mindspore.profiler.profiling import Profiler\n",
    "    profiler = Profiler(output_path=args.outputs_dir, is_detail=True, is_show_op_path=True)\n",
    "\n",
    "ds = create_dataset(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化\n",
    "\n",
    "通过 `create_dict_iterator` 函数将数据转换成字典迭代器，然后使用 `matplotlib` 模块可视化部分训练数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean = 0.5 * 255\n",
    "std = 0.5 * 255\n",
    "\n",
    "plt.figure(figsize=(12, 5), dpi=60)\n",
    "for i, data in enumerate(ds.create_dict_iterator()):\n",
    "    if i < 5:\n",
    "        show_images_a = data[\"image_A\"].asnumpy()\n",
    "        show_images_b = data[\"image_B\"].asnumpy()\n",
    "\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        show_images_a = (show_images_a[0] * std + mean).astype(np.uint8).transpose((1, 2, 0))\n",
    "        plt.imshow(show_images_a)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(2, 5, i+6)\n",
    "        show_images_b = (show_images_b[0] * std + mean).astype(np.uint8).transpose((1, 2, 0))\n",
    "        plt.imshow(show_images_b)\n",
    "        plt.axis(\"off\")\n",
    "    else:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 构建生成器\n",
    "\n",
    "本案例生成器的模型结构参考的 ResNet 模型的结构，参考原论文，对于128×128大小的输入图片采用6个残差块相连，图片大小为256×256以上的需要采用9个残差块相连，所以本文网络有9个残差块相连，超参数 `n_layers` 参数控制残差块数。\n",
    "\n",
    "生成器的结构如下所示：\n",
    "\n",
    "![CycleGAN Generator](https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/website-images/r2.3.0rc2/tutorials/application/source_zh_cn/generative/images/CycleGAN_2.jpg)\n",
    "\n",
    "具体的模型结构请参照下文代码：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上采样模块\n",
    "\n",
    "构建`ConvNormReLU`和`ConvTransposeNormReLU`部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cycle GAN network.\"\"\"\n",
    "\n",
    "from mindspore import nn\n",
    "from mindspore.common.initializer import initializer, Normal, XavierUniform\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='normal', init_gain=0.02):\n",
    "    \"\"\"\n",
    "    Initialize network weights.\n",
    "    Parameters:\n",
    "        net (Cell): Network to be initialized\n",
    "        init_type (str): The name of an initialization method: normal | xavier.\n",
    "        init_gain (float): Gain factor for normal and xavier.\n",
    "    \"\"\"\n",
    "    for _, cell in net.cells_and_names():\n",
    "        if isinstance(cell, (nn.Conv2d, nn.Conv2dTranspose)):\n",
    "            if init_type == 'normal':\n",
    "                cell.weight.set_data(initializer(Normal(init_gain), cell.weight.shape, cell.weight.dtype))\n",
    "            elif init_type == 'xavier':\n",
    "                cell.weight.set_data(initializer(XavierUniform(init_gain), cell.weight.shape, cell.weight.dtype))\n",
    "            elif init_type == 'constant':\n",
    "                cell.weight.set_data(initializer(0.001, cell.weight.shape, cell.weight.dtype))\n",
    "            else:\n",
    "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
    "        elif isinstance(cell, nn.BatchNorm2d):\n",
    "            cell.gamma.set_data(initializer('ones', cell.gamma.shape, cell.gamma.dtype))\n",
    "            cell.beta.set_data(initializer('zeros', cell.beta.shape, cell.beta.dtype))\n",
    "\n",
    "\n",
    "class ConvNormReLU(nn.Cell):\n",
    "    \"\"\"\n",
    "    Convolution fused with BatchNorm/InstanceNorm and ReLU/LackyReLU block definition.\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        out_planes (int): Output channel.\n",
    "        kernel_size (int): Input kernel size. Default: 4.\n",
    "        stride (int): Stride size for the first convolutional layer. Default: 2.\n",
    "        alpha (float): Slope of LackyReLU. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "            Default: \"CONSTANT\".\n",
    "        use_relu (bool): Use relu or not. Default: True.\n",
    "        padding (int): Pad size, if it is None, it will calculate by kernel_size. Default: None.\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_planes,\n",
    "                 out_planes,\n",
    "                 kernel_size=4,\n",
    "                 stride=2,\n",
    "                 alpha=0.2,\n",
    "                 norm_mode='batch',\n",
    "                 pad_mode='CONSTANT',\n",
    "                 use_relu=True,\n",
    "                 padding=None):\n",
    "        super(ConvNormReLU, self).__init__()\n",
    "        norm = nn.BatchNorm2d(out_planes)\n",
    "        if norm_mode == 'instance':\n",
    "            # Use BatchNorm2d with batchsize=1, affine=False, training=True instead of InstanceNorm2d\n",
    "            norm = nn.BatchNorm2d(out_planes, affine=False)\n",
    "        has_bias = (norm_mode == 'instance')\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        if pad_mode == 'CONSTANT':\n",
    "            conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, pad_mode='pad',\n",
    "                             has_bias=has_bias, padding=padding)\n",
    "            layers = [conv, norm]\n",
    "        else:\n",
    "            paddings = ((0, 0), (0, 0), (padding, padding), (padding, padding))\n",
    "            pad = nn.Pad(paddings=paddings, mode=pad_mode)\n",
    "            conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride, pad_mode='pad', has_bias=has_bias)\n",
    "            layers = [pad, conv, norm]\n",
    "        if use_relu:\n",
    "            relu = nn.ReLU()\n",
    "            if alpha > 0:\n",
    "                relu = nn.LeakyReLU(alpha)\n",
    "            layers.append(relu)\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "class ConvTransposeNormReLU(nn.Cell):\n",
    "    \"\"\"\n",
    "    ConvTranspose2d fused with BatchNorm/InstanceNorm and ReLU/LackyReLU block definition.\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        out_planes (int): Output channel.\n",
    "        kernel_size (int): Input kernel size. Default: 4.\n",
    "        stride (int): Stride size for the first convolutional layer. Default: 2.\n",
    "        alpha (float): Slope of LackyReLU. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "                        Default: \"CONSTANT\".\n",
    "        use_relu (bool): use relu or not. Default: True.\n",
    "        padding (int): pad size, if it is None, it will calculate by kernel_size. Default: None.\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_planes,\n",
    "                 out_planes,\n",
    "                 kernel_size=4,\n",
    "                 stride=2,\n",
    "                 alpha=0.2,\n",
    "                 norm_mode='batch',\n",
    "                 pad_mode='CONSTANT',\n",
    "                 use_relu=True,\n",
    "                 padding=None):\n",
    "        super(ConvTransposeNormReLU, self).__init__()\n",
    "        conv = nn.Conv2dTranspose(in_planes, out_planes, kernel_size, stride=stride, pad_mode='same')\n",
    "        norm = nn.BatchNorm2d(out_planes)\n",
    "        if norm_mode == 'instance':\n",
    "            # Use BatchNorm2d with batchsize=1, affine=False, training=True instead of InstanceNorm2d\n",
    "            norm = nn.BatchNorm2d(out_planes, affine=False)\n",
    "        has_bias = (norm_mode == 'instance')\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        if pad_mode == 'CONSTANT':\n",
    "            conv = nn.Conv2dTranspose(in_planes, out_planes, kernel_size, stride, pad_mode='same', has_bias=has_bias)\n",
    "            layers = [conv, norm]\n",
    "        else:\n",
    "            paddings = ((0, 0), (0, 0), (padding, padding), (padding, padding))\n",
    "            pad = nn.Pad(paddings=paddings, mode=pad_mode)\n",
    "            conv = nn.Conv2dTranspose(in_planes, out_planes, kernel_size, stride, pad_mode='pad', has_bias=has_bias)\n",
    "            layers = [pad, conv, norm]\n",
    "        if use_relu:\n",
    "            relu = nn.ReLU()\n",
    "            if alpha > 0:\n",
    "                relu = nn.LeakyReLU(alpha)\n",
    "            layers.append(relu)\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "构建`ResidualBlock`和`ResNetGenerator`模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ResNet Generator.\"\"\"\n",
    "\n",
    "from mindspore import nn\n",
    "from mindspore import ops\n",
    "\n",
    "\n",
    "# ResNet\n",
    "class ResidualBlock1(nn.Cell):\n",
    "    \"\"\"\n",
    "    A resnet block is a conv block with skip connections\n",
    "    We construct a conv block with build_conv_block function,\n",
    "    and implement skip connections in <forward> function..\n",
    "    Args:\n",
    "        dim (int): Input and output channel.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "            Default: \"CONSTANT\".\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, norm_mode='batch', dropout=False, pad_mode=\"CONSTANT\"):\n",
    "        super(ResidualBlock1, self).__init__()\n",
    "        self.conv1 = ConvNormReLU(dim, dim, 3, 1, 0, norm_mode, pad_mode)\n",
    "        self.conv2 = ConvNormReLU(dim, dim, 3, 1, 0, norm_mode, pad_mode, use_relu=False)\n",
    "        self.dropout = dropout\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.conv1(x)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        return x + out\n",
    "\n",
    "\n",
    "class ResNetGenerator(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet Generator of GAN.\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        ngf (int): Output channel.\n",
    "        n_layers (int): The number of ConvNormReLU blocks.\n",
    "        alpha (float): LeakyRelu slope. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "            Default: \"CONSTANT\".\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes=3, ngf=64, n_layers=9, alpha=0.2, norm_mode='batch', dropout=False,\n",
    "                 pad_mode=\"CONSTANT\"):\n",
    "        super(ResNetGenerator, self).__init__()\n",
    "        self.conv_in = ConvNormReLU(in_planes, ngf, 7, 1, alpha, norm_mode, pad_mode=pad_mode)\n",
    "        self.down_1 = ConvNormReLU(ngf, ngf * 2, 3, 2, alpha, norm_mode)\n",
    "        self.down_2 = ConvNormReLU(ngf * 2, ngf * 4, 3, 2, alpha, norm_mode)\n",
    "        layers = [ResidualBlock1(ngf * 4, norm_mode, dropout=dropout, pad_mode=pad_mode)] * n_layers\n",
    "        self.residuals = nn.SequentialCell(layers)\n",
    "        self.up_2 = ConvTransposeNormReLU(ngf * 4, ngf * 2, 3, 2, alpha, norm_mode)\n",
    "        self.up_1 = ConvTransposeNormReLU(ngf * 2, ngf, 3, 2, alpha, norm_mode)\n",
    "        if pad_mode == \"CONSTANT\":\n",
    "            self.conv_out = nn.Conv2d(ngf, 3, kernel_size=7, stride=1, pad_mode='pad', padding=3)\n",
    "        else:\n",
    "            pad = nn.Pad(paddings=((0, 0), (0, 0), (3, 3), (3, 3)), mode=pad_mode)\n",
    "            conv = nn.Conv2d(ngf, 3, kernel_size=7, stride=1, pad_mode='pad')\n",
    "            self.conv_out = nn.SequentialCell([pad, conv])\n",
    "        self.activate = ops.Tanh()\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv_in(x)\n",
    "        x = self.down_1(x)\n",
    "        x = self.down_2(x)\n",
    "        x = self.residuals(x)\n",
    "        x = self.up_2(x)\n",
    "        x = self.up_1(x)\n",
    "        output = self.conv_out(x)\n",
    "        return self.activate(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DepthResNet和Unet\n",
    "\n",
    "生成器的模型结构还可以参考`DepthResNet`和`Unet`的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DepthResNet\n",
    "class ResidualBlock(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet residual block definition.\n",
    "    We construct a conv block with build_conv_block function,\n",
    "    and implement skip connections in <forward> function..\n",
    "    Args:\n",
    "        dim (int): Input and output channel.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "            Default: \"CONSTANT\".\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, norm_mode='batch', dropout=False, pad_mode=\"CONSTANT\"):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = ConvNormReLU(dim, dim, 3, 1, 0.2, norm_mode, pad_mode)\n",
    "        self.conv2 = ConvNormReLU(dim, dim, 3, 1, 0.2, norm_mode, pad_mode)\n",
    "        self.dropout = dropout\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.conv1(x)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        return x + out\n",
    "\n",
    "\n",
    "class DepthResNetGenerator(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet Generator of GAN.\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        ngf (int): Output channel.\n",
    "        n_layers (int): The number of ConvNormReLU blocks.\n",
    "        alpha (float): LeakyRelu slope. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "        pad_mode (str): Specifies padding mode. The optional values are \"CONSTANT\", \"REFLECT\", \"SYMMETRIC\".\n",
    "            Default: \"CONSTANT\".\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes=3, ngf=64, n_layers=9, alpha=0.2, norm_mode='batch', dropout=False,\n",
    "                 pad_mode=\"CONSTANT\"):\n",
    "        super(DepthResNetGenerator, self).__init__()\n",
    "        conv_in1 = nn.Conv2d(in_planes, ngf, kernel_size=3, stride=1, has_bias=True)\n",
    "        conv_in2 = ConvNormReLU(ngf, ngf, 7, 1, alpha, norm_mode, pad_mode=pad_mode)\n",
    "        self.conv_in = nn.SequentialCell([conv_in1, conv_in2])\n",
    "        down_1 = ConvNormReLU(ngf, ngf * 2, 3, 2, alpha, norm_mode)\n",
    "        Res1 = ResidualBlock(ngf * 2, norm_mode, dropout=dropout, pad_mode=pad_mode)\n",
    "        self.down_1 = nn.SequentialCell([down_1, Res1])\n",
    "        down_2 = ConvNormReLU(ngf * 2, ngf * 3, 3, 2, alpha, norm_mode)\n",
    "        Res2 = ResidualBlock(ngf * 3, norm_mode, dropout=dropout, pad_mode=pad_mode)\n",
    "        self.down_2 = nn.SequentialCell([down_2, Res2])\n",
    "        self.down_3 = ConvNormReLU(ngf * 3, ngf * 4, 3, 2, alpha, norm_mode)\n",
    "        layers = [ResidualBlock(ngf * 4, norm_mode, dropout=dropout, pad_mode=pad_mode)] * (n_layers-5)\n",
    "        self.residuals = nn.SequentialCell(layers)\n",
    "        up_3 = ConvTransposeNormReLU(ngf * 4, ngf * 3, 3, 2, alpha, norm_mode)\n",
    "        Res3 = ResidualBlock(ngf * 3, norm_mode, dropout=dropout, pad_mode=pad_mode)\n",
    "        self.up_3 = nn.SequentialCell([up_3, Res3])\n",
    "        up_2 = ConvTransposeNormReLU(ngf * 3, ngf * 2, 3, 2, alpha, norm_mode)\n",
    "        Res4 = ResidualBlock(ngf * 2, norm_mode, dropout=dropout, pad_mode=pad_mode)\n",
    "        self.up_2 = nn.SequentialCell([up_2, Res4])\n",
    "        up_1 = ConvTransposeNormReLU(ngf * 2, ngf, 3, 2, alpha, norm_mode)\n",
    "        Res5 = ResidualBlock(ngf, norm_mode, dropout=dropout, pad_mode=pad_mode)\n",
    "        self.up_1 = nn.SequentialCell([up_1, Res5])\n",
    "        tanh = nn.Tanh()\n",
    "        if pad_mode == \"CONSTANT\":\n",
    "            conv_out1 = nn.Conv2d(ngf, 3, kernel_size=7, stride=1, has_bias=True, pad_mode='pad', padding=3)\n",
    "            conv_out2 = nn.Conv2d(3, 3, kernel_size=3, stride=1, has_bias=True)\n",
    "            self.conv_out = nn.SequentialCell([conv_out1, tanh, conv_out2, tanh])\n",
    "        else:\n",
    "            pad = nn.Pad(paddings=((0, 0), (0, 0), (3, 3), (3, 3)), mode=pad_mode)\n",
    "            conv = nn.Conv2d(ngf, 3, kernel_size=7, stride=1, pad_mode='pad')\n",
    "            self.conv_out = nn.SequentialCell([pad, conv, tanh])\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\" construct network \"\"\"\n",
    "        x = self.conv_in(x)\n",
    "        x = self.down_1(x)\n",
    "        x = self.down_2(x)\n",
    "        x = self.down_3(x)\n",
    "        x = self.residuals(x)\n",
    "        x = self.up_3(x)\n",
    "        x = self.up_2(x)\n",
    "        x = self.up_1(x)\n",
    "        output = self.conv_out(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Unet\n",
    "class UnetGenerator(nn.Cell):\n",
    "    \"\"\"\n",
    "    Unet-based generator.\n",
    "\n",
    "    Args:\n",
    "        in_planes (int): the number of channels in input images.\n",
    "        out_planes (int): the number of channels in output images.\n",
    "        ngf (int): the number of filters in the last conv layer.\n",
    "        n_layers (int): the number of downsamplings in UNet.\n",
    "        alpha (float): LeakyRelu slope. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes, out_planes, ngf=64, n_layers=7, alpha=0.2, norm_mode='bn', dropout=False):\n",
    "        super(UnetGenerator, self).__init__()\n",
    "        # construct unet structure\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, in_planes=None, submodule=None,\n",
    "                                             norm_mode=norm_mode, innermost=True)\n",
    "        for _ in range(n_layers - 5):\n",
    "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, in_planes=None, submodule=unet_block,\n",
    "                                                 norm_mode=norm_mode, dropout=dropout)\n",
    "        # gradually reduce the number of filters from ngf * 8 to ngf\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, in_planes=None, submodule=unet_block,\n",
    "                                             norm_mode=norm_mode)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, in_planes=None, submodule=unet_block,\n",
    "                                             norm_mode=norm_mode)\n",
    "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, in_planes=None, submodule=unet_block, norm_mode=norm_mode)\n",
    "        self.model = UnetSkipConnectionBlock(out_planes, ngf, in_planes=in_planes, submodule=unet_block,\n",
    "                                             outermost=True, norm_mode=norm_mode)\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class UnetSkipConnectionBlock(nn.Cell):\n",
    "    \"\"\"Unet submodule with skip connection.\n",
    "\n",
    "    Args:\n",
    "        outer_nc (int): The number of filters in the outer conv layer\n",
    "        inner_nc (int): The number of filters in the inner conv layer\n",
    "        in_planes (int): The number of channels in input images/features\n",
    "        dropout (bool): Use dropout or not. Default: False.\n",
    "        submodule (Cell): Previously defined submodules\n",
    "        outermost (bool): If this module is the outermost module\n",
    "        innermost (bool): If this module is the innermost module\n",
    "        alpha (float): LeakyRelu slope. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, outer_nc, inner_nc, in_planes=None, dropout=False,\n",
    "                 submodule=None, outermost=False, innermost=False, alpha=0.2, norm_mode='batch'):\n",
    "        super(UnetSkipConnectionBlock, self).__init__()\n",
    "        downnorm = nn.BatchNorm2d(inner_nc)\n",
    "        upnorm = nn.BatchNorm2d(outer_nc)\n",
    "        use_bias = False\n",
    "        if norm_mode == 'instance':\n",
    "            downnorm = nn.BatchNorm2d(inner_nc, affine=False)\n",
    "            upnorm = nn.BatchNorm2d(outer_nc, affine=False)\n",
    "            use_bias = True\n",
    "        if in_planes is None:\n",
    "            in_planes = outer_nc\n",
    "        downconv = nn.Conv2d(in_planes, inner_nc, kernel_size=4,\n",
    "                             stride=2, padding=1, has_bias=use_bias, pad_mode='pad')\n",
    "        downrelu = nn.LeakyReLU(alpha)\n",
    "        uprelu = nn.ReLU()\n",
    "\n",
    "        if outermost:\n",
    "            upconv = nn.Conv2dTranspose(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, pad_mode='pad')\n",
    "            down = [downconv]\n",
    "            up = [uprelu, upconv, nn.Tanh()]\n",
    "            model = down + [submodule] + up\n",
    "        elif innermost:\n",
    "            upconv = nn.Conv2dTranspose(inner_nc, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, has_bias=use_bias, pad_mode='pad')\n",
    "            down = [downrelu, downconv]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "            model = down + up\n",
    "        else:\n",
    "            upconv = nn.Conv2dTranspose(inner_nc * 2, outer_nc,\n",
    "                                        kernel_size=4, stride=2,\n",
    "                                        padding=1, has_bias=use_bias, pad_mode='pad')\n",
    "            down = [downrelu, downconv, downnorm]\n",
    "            up = [uprelu, upconv, upnorm]\n",
    "\n",
    "            model = down + [submodule] + up\n",
    "            if dropout:\n",
    "                model.append(nn.Dropout(0.5))\n",
    "\n",
    "        self.model = nn.SequentialCell(model)\n",
    "        self.skip_connections = not outermost\n",
    "        self.concat = ops.Concat(axis=1)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out = self.model(x)\n",
    "        if self.skip_connections:\n",
    "            if x.shape[-1] != out.shape[-1]:\n",
    "                out = ops.ResizeBilinear(x.shape)(out)\n",
    "            out = self.concat((out, x))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例化生成器\n",
    "\n",
    "通过`model`参数来指定生成器的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(args):\n",
    "    \"\"\"\n",
    "    This class implements the CycleGAN model, for learning image-to-image translation without paired data.\n",
    "\n",
    "    The model training requires '--dataset_mode unaligned' dataset.\n",
    "    By default, it uses a '--netG resnet_9blocks' ResNet generator,\n",
    "    a '--netD basic' discriminator (PatchGAN introduced by pix2pix),\n",
    "    and a least-square GANs objective ('--gan_mode lsgan').\n",
    "    \"\"\"\n",
    "    if args.model == \"ResNet\":\n",
    "        net = ResNetGenerator(in_planes=args.in_planes, ngf=args.ngf, n_layers=args.gl_num,\n",
    "                              alpha=args.slope, norm_mode=args.norm_mode, dropout=args.need_dropout,\n",
    "                              pad_mode=args.pad_mode)\n",
    "        init_weights(net, args.init_type, args.init_gain)\n",
    "    elif args.model == \"DepthResNet\":\n",
    "        net = DepthResNetGenerator(in_planes=args.in_planes, ngf=args.ngf, n_layers=args.gl_num,\n",
    "                                   alpha=args.slope, norm_mode=args.norm_mode, dropout=args.need_dropout,\n",
    "                                   pad_mode=args.pad_mode)\n",
    "        init_weights(net, args.init_type, args.init_gain)\n",
    "    elif args.model == \"UNet\":\n",
    "        if args.image_size % (2 ** (args.gl_num + 1)) != 0:\n",
    "            raise ValueError(f\"For UNet Generator, the image_size must be a multiple of 2 ** (gl_num + 1), \"\n",
    "                             f\"please adjust the image_size or gl_num, now the image_size is {args.image_size} \"\n",
    "                             f\"gl_num is {args.gl_num}, it is recommended that gl_num = 7.\")\n",
    "        net = UnetGenerator(in_planes=args.in_planes, out_planes=args.in_planes, ngf=args.ngf, n_layers=args.gl_num,\n",
    "                            alpha=args.slope, norm_mode=args.norm_mode, dropout=args.need_dropout)\n",
    "        init_weights(net, args.init_type, args.init_gain)\n",
    "    else:\n",
    "        raise NotImplementedError(f'Model {args.model} not recognized.')\n",
    "    return net\n",
    "\n",
    "# args = get_args(\"train\")\n",
    "args.model = \"ResNet\"\n",
    "\n",
    "net_rg_a = get_generator(args)\n",
    "net_rg_a.update_parameters_name('net_rg_a.')\n",
    "\n",
    "net_rg_b = get_generator(args)\n",
    "net_rg_b.update_parameters_name('net_rg_b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 构建判别器\n",
    "\n",
    "判别器其实是一个二分类网络模型，输出判定该图像为真实图的概率。网络模型使用的是 Patch 大小为 70x70 的 PatchGANs 模型。通过一系列的 `Conv2d` 、 `BatchNorm2d` 和 `LeakyReLU` 层对其进行处理，最后通过 Sigmoid 激活函数得到最终概率。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Cell):\n",
    "    \"\"\"\n",
    "    Discriminator of GAN.\n",
    "    Args:\n",
    "        in_planes (int): Input channel.\n",
    "        ndf (int): Output channel.\n",
    "        n_layers (int): The number of ConvNormReLU blocks.\n",
    "        alpha (float): LeakyRelu slope. Default: 0.2.\n",
    "        norm_mode (str): Specifies norm method. The optional values are \"batch\", \"instance\".\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    Examples:\n",
    "        >>> Discriminator(3, 64, 3)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes=3, ndf=64, n_layers=3, alpha=0.2, norm_mode='batch'):\n",
    "        super(Discriminator, self).__init__()\n",
    "        kernel_size = 4\n",
    "        layers = [\n",
    "            nn.Conv2d(in_planes, ndf, kernel_size, 2, pad_mode='pad', padding=1),\n",
    "            nn.LeakyReLU(alpha)\n",
    "        ]\n",
    "        nf_mult = ndf\n",
    "        for i in range(1, n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** i, 8) * ndf\n",
    "            layers.append(ConvNormReLU(nf_mult_prev, nf_mult, kernel_size, 2, alpha, norm_mode, padding=1))\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8) * ndf\n",
    "        layers.append(ConvNormReLU(nf_mult_prev, nf_mult, kernel_size, 1, alpha, norm_mode, padding=1))\n",
    "        layers.append(nn.Conv2d(nf_mult, 1, kernel_size, 1, pad_mode='pad', padding=1))\n",
    "        self.features = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.features(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "def get_discriminator(args):\n",
    "    \"\"\"Return discriminator by args.\"\"\"\n",
    "    net = Discriminator(in_planes=args.in_planes, ndf=args.ndf, n_layers=args.dl_num,\n",
    "                        alpha=args.slope, norm_mode=args.norm_mode)\n",
    "    init_weights(net, args.init_type, args.init_gain)\n",
    "    return net\n",
    "\n",
    "net_d_a = get_discriminator(args)\n",
    "net_d_a.update_parameters_name('net_d_a.')\n",
    "\n",
    "net_d_b = get_discriminator(args)\n",
    "net_d_b.update_parameters_name('net_d_b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器和损失函数\n",
    "\n",
    "根据不同模型需要单独的设置优化器，这是训练过程决定的。\n",
    "\n",
    "对生成器 $G$ 及其判别器 $D_{Y}$ ，目标损失函数定义为:\n",
    "\n",
    "$$L_{GAN}(G,D_Y,X,Y)=E_{y-p_{data}(y)}[logD_Y(y)]+E_{x-p_{data}(x)}[log(1-D_Y(G(x)))]$$\n",
    "\n",
    "其中 $G$ 试图生成看起来与 $Y$ 中的图像相似的图像 $G(x)$ ，而 $D_{Y}$ 的目标是区分翻译样本 $G(x)$ 和真实样本 $y$ ，生成器的目标是最小化这个损失函数以此来对抗判别器。即 $ min_{G} max_{D_{Y}}L_{GAN}(G,D_{Y} ,X,Y )$ 。\n",
    "\n",
    "单独的对抗损失不能保证所学函数可以将单个输入映射到期望的输出，为了进一步减少可能的映射函数的空间，学习到的映射函数应该是周期一致的，例如对于 $X$ 的每个图像 $x$ ，图像转换周期应能够将 $x$ 带回原始图像，可以称之为正向循环一致性，即 $x→G(x)→F(G(x))\\approx x$ 。对于 $Y$ ，类似的 $x→G(x)→F(G(x))\\approx x$ 。可以理解采用了一个循环一致性损失来激励这种行为。\n",
    "\n",
    "循环一致损失函数定义如下：\n",
    "\n",
    "$$L_{cyc}(G,F)=E_{x-p_{data}(x)}[\\Vert F(G(x))-x\\Vert_{1}]+E_{y-p_{data}(y)}[\\Vert G(F(y))-y\\Vert_{1}]$$\n",
    "\n",
    "循环一致损失能够保证重建图像 $F(G(x))$ 与输入图像 $x$ 紧密匹配。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cycle GAN losses\"\"\"\n",
    "\n",
    "from mindspore import dtype\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor\n",
    "\n",
    "\n",
    "class BCEWithLogits(nn.Cell):\n",
    "    \"\"\"\n",
    "    BCEWithLogits creates a criterion to measure the Binary Cross Entropy between the true labels and\n",
    "    predicted labels with sigmoid logits.\n",
    "    Args:\n",
    "        reduction (str): Specifies the reduction to be applied to the output.\n",
    "            Its value must be one of 'none', 'mean', 'sum'. Default: 'none'.\n",
    "    Outputs:\n",
    "        Tensor or Scalar, if `reduction` is 'none', then output is a tensor and has the same shape as `inputs`.\n",
    "        Otherwise, the output is a scalar.\n",
    "    \"\"\"\n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(BCEWithLogits, self).__init__()\n",
    "        if reduction is None:\n",
    "            reduction = 'none'\n",
    "        if reduction not in ('mean', 'sum', 'none'):\n",
    "            raise ValueError(f\"reduction method for {reduction.lower()} is not supported\")\n",
    "\n",
    "        self.loss = ops.SigmoidCrossEntropyWithLogits()\n",
    "        self.reduce = False\n",
    "        if reduction == 'sum':\n",
    "            self.reduce_mode = ops.ReduceSum()\n",
    "            self.reduce = True\n",
    "        elif reduction == 'mean':\n",
    "            self.reduce_mode = ops.ReduceMean()\n",
    "            self.reduce = True\n",
    "    def construct(self, predict, target):\n",
    "        loss = self.loss(predict, target)\n",
    "        if self.reduce:\n",
    "            loss = self.reduce_mode(loss)\n",
    "        return loss\n",
    "\n",
    "def get_lr(args):\n",
    "    \"\"\"\n",
    "    Learning rate generator.\n",
    "    For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n",
    "    and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n",
    "    \"\"\"\n",
    "    if args.lr_policy == 'linear':\n",
    "        lrs = [args.lr] * args.dataset_size * args.n_epochs\n",
    "        lr_epoch = 0\n",
    "        for epoch in range(args.n_epochs_decay):\n",
    "            lr_epoch = args.lr * (args.n_epochs_decay - epoch) / args.n_epochs_decay\n",
    "            lrs += [lr_epoch] * args.dataset_size\n",
    "        lrs += [lr_epoch] * args.dataset_size * (args.max_epoch - args.n_epochs_decay - args.n_epochs)\n",
    "        return Tensor(np.array(lrs).astype(np.float32))\n",
    "    return args.lr\n",
    "\n",
    "# 构建生成器，判别器优化器\n",
    "optimizer_rg_a = nn.Adam(net_rg_a.trainable_params(), get_lr(args), beta1=args.beta1)\n",
    "optimizer_rg_b = nn.Adam(net_rg_b.trainable_params(), get_lr(args), beta1=args.beta1)\n",
    "\n",
    "optimizer_d_a = nn.Adam(net_d_a.trainable_params(), get_lr(args), beta1=args.beta1)\n",
    "optimizer_d_b = nn.Adam(net_d_b.trainable_params(), get_lr(args), beta1=args.beta1)\n",
    "\n",
    "# GAN网络损失函数\n",
    "def get_loss_fn(args, reduction='mean'):\n",
    "    loss_fn = None\n",
    "    if args.gan_mode == \"lsgan\":\n",
    "        loss_fn = nn.MSELoss(reduction)\n",
    "    elif args.gan_mode == \"vanilla\":\n",
    "        loss_fn = BCEWithLogits(reduction)\n",
    "    else:\n",
    "        raise NotImplementedError(f'GANLoss {mode} not recognized, we support lsgan and vanilla.') \n",
    "    return loss_fn\n",
    "\n",
    "loss_fn = get_loss_fn(args)\n",
    "l1_loss = nn.L1Loss(\"mean\")\n",
    "\n",
    "def gan_loss(predict, target):\n",
    "    target = ops.cast(target, ops.dtype(predict))\n",
    "    target = ops.ones_like(predict) * target\n",
    "    loss = loss_fn(predict, target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向计算\n",
    "\n",
    "搭建模型前向计算损失的过程，过程如下代码。\n",
    "\n",
    "为了减少模型振荡[1]，这里遵循 Shrivastava 等人的策略[2]，使用生成器生成图像的历史数据而不是生成器生成的最新图像数据来更新鉴别器。这里创建 `ImagePool` 类，保留了一个图像缓冲区，用于存储生成器生成前的50个图像。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(img_a, img_b, use_identity=True):\n",
    "    fake_a = net_rg_b(img_b)\n",
    "    fake_b = net_rg_a(img_a)\n",
    "    rec_a = net_rg_b(fake_b)\n",
    "    rec_b = net_rg_a(fake_a)\n",
    "    if use_identity:\n",
    "        identity_a = net_rg_b(img_a)\n",
    "        identity_b = net_rg_a(img_b)\n",
    "    else:\n",
    "        identity_a = ops.ones_like(img_a)\n",
    "        identity_b = ops.ones_like(img_b)\n",
    "    return fake_a, fake_b, rec_a, rec_b, identity_a, identity_b\n",
    "\n",
    "args.lambda_A = 10.0\n",
    "args.lambda_B = 10.0\n",
    "args.lambda_idt = 0.5\n",
    "\n",
    "def generator_forward(img_a, img_b):\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    fake_a, fake_b, rec_a, rec_b, identity_a, identity_b = generator(img_a, img_b, args.lambda_idt > 0)\n",
    "    loss_g_a = gan_loss(net_d_b(fake_b), true)\n",
    "    loss_g_b = gan_loss(net_d_a(fake_a), true)\n",
    "    loss_c_a = l1_loss(rec_a, img_a) * args.lambda_A\n",
    "    loss_c_b = l1_loss(rec_b, img_b) * args.lambda_B\n",
    "    if args.lambda_idt > 0:\n",
    "        loss_idt_a = l1_loss(identity_a, img_a) * args.lambda_A * args.lambda_idt\n",
    "        loss_idt_b = l1_loss(identity_b, img_b) * args.lambda_B * args.lambda_idt\n",
    "    else:\n",
    "        loss_idt_a = 0\n",
    "        loss_idt_b = 0\n",
    "    loss_g = loss_g_a + loss_g_b + loss_c_a + loss_c_b + loss_idt_a + loss_idt_b\n",
    "    return fake_a, fake_b, loss_g, loss_g_a, loss_g_b, loss_c_a, loss_c_b, loss_idt_a, loss_idt_b\n",
    "\n",
    "def generator_forward_grad(img_a, img_b):\n",
    "    _, _, loss_g, _, _, _, _, _, _ = generator_forward(img_a, img_b)\n",
    "    return loss_g\n",
    "\n",
    "def discriminator_forward(img_a, img_b, fake_a, fake_b):\n",
    "    false = Tensor(False, dtype.bool_)\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    d_fake_a = net_d_a(fake_a)\n",
    "    d_img_a = net_d_a(img_a)\n",
    "    d_fake_b = net_d_b(fake_b)\n",
    "    d_img_b = net_d_b(img_b)\n",
    "    loss_d_a = gan_loss(d_fake_a, false) + gan_loss(d_img_a, true)\n",
    "    loss_d_b = gan_loss(d_fake_b, false) + gan_loss(d_img_b, true)\n",
    "    loss_d = (loss_d_a + loss_d_b) * 0.5\n",
    "    return loss_d\n",
    "\n",
    "def discriminator_forward_a(img_a, fake_a):\n",
    "    false = Tensor(False, dtype.bool_)\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    d_fake_a = net_d_a(fake_a)\n",
    "    d_img_a = net_d_a(img_a)\n",
    "    loss_d_a = gan_loss(d_fake_a, false) + gan_loss(d_img_a, true)\n",
    "    return loss_d_a\n",
    "\n",
    "def discriminator_forward_b(img_b, fake_b):\n",
    "    false = Tensor(False, dtype.bool_)\n",
    "    true = Tensor(True, dtype.bool_)\n",
    "    d_fake_b = net_d_b(fake_b)\n",
    "    d_img_b = net_d_b(img_b)\n",
    "    loss_d_b = gan_loss(d_fake_b, false) + gan_loss(d_img_b, true)\n",
    "    return loss_d_b\n",
    "\n",
    "\n",
    "class ImagePool():\n",
    "    \"\"\"\n",
    "    This class implements an image buffer that stores previously generated images.\n",
    "    This buffer enables us to update discriminators using a history of generated images\n",
    "    rather than the ones produced by the latest generators.\n",
    "    \"\"\"\n",
    "    def __init__(self, pool_size):\n",
    "        \"\"\"\n",
    "        Initialize the ImagePool class\n",
    "        Args:\n",
    "            pool_size (int): the size of image buffer, if pool_size=0, no buffer will be created.\n",
    "        \"\"\"\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:  # create an empty pool\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        \"\"\"\n",
    "        Return an image from the pool.\n",
    "        Args:\n",
    "            images: the latest generated images from the generator\n",
    "        Returns images Tensor from the buffer.\n",
    "        By 50/100, the buffer will return input images.\n",
    "        By 50/100, the buffer will return images previously stored in the buffer,\n",
    "        and insert the current images to the buffer.\n",
    "        \"\"\"\n",
    "        if isinstance(images, Tensor):\n",
    "            images = images.asnumpy()\n",
    "        if self.pool_size == 0:  # if the buffer size is 0, do nothing\n",
    "            return Tensor(images)\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            if self.num_imgs < self.pool_size:   # if the buffer is not full; keep inserting current images to the buffer\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:  # by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer\n",
    "                    random_id = random.randint(0, self.pool_size - 1)  # randint is inclusive\n",
    "                    tmp = self.images[random_id].copy()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:       # by another 50% chance, the buffer will return the current image\n",
    "                    return_images.append(image)\n",
    "        return_images = np.array(return_images)   # collect all the images and return\n",
    "        if len(return_images.shape) != 4:\n",
    "            raise ValueError(\"img should be 4d, but get shape {}\".format(return_images.shape))\n",
    "        return Tensor(return_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算梯度和反向传播\n",
    "\n",
    "其中梯度计算也是分开不同的模型来进行的，详情见如下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import value_and_grad\n",
    "\n",
    "# 实例化求梯度的方法\n",
    "grad_g_a = value_and_grad(generator_forward_grad, None, net_rg_a.trainable_params())\n",
    "grad_g_b = value_and_grad(generator_forward_grad, None, net_rg_b.trainable_params())\n",
    "\n",
    "grad_d_a = value_and_grad(discriminator_forward_a, None, net_d_a.trainable_params())\n",
    "grad_d_b = value_and_grad(discriminator_forward_b, None, net_d_b.trainable_params())\n",
    "\n",
    "# 计算生成器的梯度，反向传播更新参数\n",
    "def train_step_g(img_a, img_b):\n",
    "    net_d_a.set_grad(False)\n",
    "    net_d_b.set_grad(False)\n",
    "    \n",
    "    fake_a, fake_b, lg, lga, lgb, lca, lcb, lia, lib = generator_forward(img_a, img_b)\n",
    "    \n",
    "    _, grads_g_a = grad_g_a(img_a, img_b)\n",
    "    _, grads_g_b = grad_g_b(img_a, img_b)\n",
    "    optimizer_rg_a(grads_g_a)\n",
    "    optimizer_rg_b(grads_g_b)\n",
    "\n",
    "    return fake_a, fake_b, lg, lga, lgb, lca, lcb, lia, lib\n",
    "\n",
    "# 计算判别器的梯度，反向传播更新参数\n",
    "def train_step_d(img_a, img_b, fake_a, fake_b):\n",
    "    net_d_a.set_grad(True)\n",
    "    net_d_b.set_grad(True)\n",
    "\n",
    "    loss_d_a, grads_d_a = grad_d_a(img_a, fake_a)\n",
    "    loss_d_b, grads_d_b = grad_d_b(img_b, fake_b)\n",
    "\n",
    "    loss_d = (loss_d_a + loss_d_b) * 0.5\n",
    "\n",
    "    optimizer_d_a(grads_d_a)\n",
    "    optimizer_d_b(grads_d_b)\n",
    "\n",
    "    return loss_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "训练分为两个主要部分：训练判别器和训练生成器，在前文的判别器损失函数中，论文采用了最小二乘损失代替负对数似然目标。\n",
    "\n",
    "- 训练判别器：训练判别器的目的是最大程度地提高判别图像真伪的概率。按照论文的方法需要训练判别器来最小化 $E_{y-p_{data}(y)}[(D(y)-1)^2]$ ；\n",
    "\n",
    "- 训练生成器：如 CycleGAN 论文所述，我们希望通过最小化 $E_{x-p_{data}(x)}[(D(G(x)-1)^2]$ 来训练生成器，以产生更好的虚假图像。\n",
    "\n",
    "下面定义了生成器和判别器的训练过程：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练过程中用到的工具\n",
    "\n",
    "创建图片保存、获取学习率、加载权重的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "\n",
    "def save_image(img, img_path, random_id=0):\n",
    "    \"\"\"Save a numpy image to the disk\n",
    "    Parameters:\n",
    "        img (numpy array / Tensor): image to save.\n",
    "        image_path (str): the path of the image.\n",
    "        random_id (int): the number range in 0 ~ batch_size to be saved.\n",
    "    \"\"\"\n",
    "    if isinstance(img, Tensor):\n",
    "        img = img.asnumpy()\n",
    "    elif not isinstance(img, np.ndarray):\n",
    "        raise ValueError(\"img should be Tensor or numpy array, but get {}\".format(type(img)))\n",
    "    img = decode_image(img, random_id)\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil.save(img_path)\n",
    "\n",
    "\n",
    "def decode_image(img, random_id=0):\n",
    "    \"\"\"Decode a [1, C, H, W] Tensor to image numpy array.\"\"\"\n",
    "    mean = 0.5 * 255\n",
    "    std = 0.5 * 255\n",
    "    \n",
    "    return (img[random_id] * std + mean).astype(np.uint8).transpose((1, 2, 0))\n",
    "\n",
    "\n",
    "def load_ckpt(args, G_A, G_B, D_A=None, D_B=None):\n",
    "    \"\"\"Load parameter from checkpoint.\"\"\"\n",
    "    if args.G_A_ckpt is not None:\n",
    "        param_GA = load_checkpoint(args.G_A_ckpt)\n",
    "        load_param_into_net(G_A, param_GA)\n",
    "    if args.G_B_ckpt is not None:\n",
    "        param_GB = load_checkpoint(args.G_B_ckpt)\n",
    "        load_param_into_net(G_B, param_GB)\n",
    "    if D_A is not None and args.D_A_ckpt is not None:\n",
    "        param_DA = load_checkpoint(args.D_A_ckpt)\n",
    "        load_param_into_net(D_A, param_DA)\n",
    "    if D_B is not None and args.D_B_ckpt is not None:\n",
    "        param_DB = load_checkpoint(args.D_B_ckpt)\n",
    "        load_param_into_net(D_B, param_DB)\n",
    "\n",
    "\n",
    "def enable_batch_statistics(net):\n",
    "    \"\"\"Enable batch statistics in all BatchNorms\"\"\"\n",
    "    if isinstance(net, nn.BatchNorm2d):\n",
    "        net.use_batch_statistics = True\n",
    "    else:\n",
    "        for cell in net.cells():\n",
    "            enable_batch_statistics(cell)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义Reporter类\n",
    "\n",
    "监听训练过程中的数据，打印日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reporter class.\"\"\"\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "from mindspore import save_checkpoint\n",
    "\n",
    "\n",
    "class Reporter(logging.Logger):\n",
    "    \"\"\"\n",
    "    This class includes several functions that can save images/checkpoints and print/save logging information.\n",
    "    Args:\n",
    "        args (class): Option class.\n",
    "    \"\"\"\n",
    "    def __init__(self, args):\n",
    "        super(Reporter, self).__init__(\"cyclegan\")\n",
    "        self.log_dir = os.path.join(args.outputs_dir, 'log')\n",
    "        self.ckpts_dir = os.path.join(args.outputs_dir, \"ckpt\")\n",
    "        self.imgs_dir = os.path.join(args.outputs_dir, \"imgs\")\n",
    "        if not os.path.exists(self.log_dir):\n",
    "            os.makedirs(self.log_dir, exist_ok=True)\n",
    "        if not os.path.exists(self.ckpts_dir):\n",
    "            os.makedirs(self.ckpts_dir, exist_ok=True)\n",
    "        if not os.path.exists(self.imgs_dir):\n",
    "            os.makedirs(self.imgs_dir, exist_ok=True)\n",
    "        self.rank = args.rank\n",
    "        self.save_checkpoint_epochs = args.save_checkpoint_epochs\n",
    "        self.save_imgs = args.save_imgs\n",
    "        # console handler\n",
    "        console = logging.StreamHandler()\n",
    "        console.setLevel(logging.INFO)\n",
    "        formatter = logging.Formatter('%(message)s')\n",
    "        console.setFormatter(formatter)\n",
    "        self.addHandler(console)\n",
    "        # file handler\n",
    "        log_name = datetime.now().strftime('%Y-%m-%d_time_%H_%M_%S') + '_rank_{}.log'.format(self.rank)\n",
    "        self.log_fn = os.path.join(self.log_dir, log_name)\n",
    "        fh = logging.FileHandler(self.log_fn)\n",
    "        fh.setLevel(logging.INFO)\n",
    "        fh.setFormatter(formatter)\n",
    "        self.addHandler(fh)\n",
    "        self.save_args(args)\n",
    "        self.step = 0\n",
    "        self.epoch = 0\n",
    "        self.batch_size = args.batch_size\n",
    "        self.n_steps = args.dataset_size // args.batch_size\n",
    "        print(args.dataset_size, self.n_steps)\n",
    "        self.dataset_size = args.dataset_size // args.device_num\n",
    "        self.save_img_nums = args.save_img_nums\n",
    "        self.device_num = args.device_num\n",
    "        self.print_iter = args.print_iter\n",
    "        self.G_loss = []\n",
    "        self.D_loss = []\n",
    "\n",
    "    def info(self, msg, *args, **kwargs):\n",
    "        if self.isEnabledFor(logging.INFO):\n",
    "            self._log(logging.INFO, msg, args, **kwargs)\n",
    "\n",
    "    def save_args(self, args):\n",
    "        self.info('Args:')\n",
    "        args_dict = vars(args)\n",
    "        for key in args_dict.keys():\n",
    "            self.info('--> %s: %s', key, args_dict[key])\n",
    "        self.info('')\n",
    "\n",
    "    def epoch_start(self):\n",
    "        self.step_start_time = time.time()\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.step = 0\n",
    "        self.epoch += 1\n",
    "        self.G_loss = []\n",
    "        self.D_loss = []\n",
    "\n",
    "        random.seed()\n",
    "        self.random_imgs_out_steps = random.sample(range(1, self.n_steps+1), self.save_img_nums)\n",
    "        \n",
    "        self.imgs_epoch_dir = os.path.join(self.imgs_dir, str(self.epoch))\n",
    "        if not os.path.exists(self.imgs_epoch_dir):\n",
    "            os.makedirs(self.imgs_epoch_dir, exist_ok=True)\n",
    "\n",
    "    def step_end(self, res_G, res_D):\n",
    "        \"\"\"print log when step end.\"\"\"\n",
    "        self.step += 1\n",
    "        loss_D = float(res_D.asnumpy())\n",
    "        res = []\n",
    "        for item in res_G[2:]:\n",
    "            res.append(float(item.asnumpy()))\n",
    "        self.G_loss.append(res[0])\n",
    "        self.D_loss.append(loss_D)\n",
    "        if self.step % self.print_iter == 0:\n",
    "            step_cost = (time.time() - self.step_start_time) * 1000 / self.print_iter\n",
    "            losses = \"G_loss: {:.2f}, D_loss:{:.2f}, loss_G_A: {:.2f}, loss_G_B: {:.2f}, loss_C_A: {:.2f},\"\\\n",
    "                     \"loss_C_B: {:.2f}, loss_idt_A: {:.2f}, loss_idt_B：{:.2f}\".format(\n",
    "                         res[0], loss_D, res[1], res[2], res[3], res[4], res[5], res[6])\n",
    "            self.info(\"Epoch[{}] [{}/{}] step cost: {:.2f} ms, {}\".format(\n",
    "                self.epoch, self.step, self.dataset_size, step_cost, losses))\n",
    "            self.step_start_time = time.time()\n",
    "\n",
    "    def epoch_end(self):\n",
    "        \"\"\"print log and save checkpoints when epoch end.\"\"\"\n",
    "        epoch_cost = (time.time() - self.epoch_start_time) * 1000\n",
    "        per_step_time = epoch_cost / self.dataset_size\n",
    "        mean_loss_G = sum(self.G_loss) / self.dataset_size\n",
    "        mean_loss_D = sum(self.D_loss) / self.dataset_size\n",
    "        self.info(\"Epoch [{}] total cost: {:.2f} ms, per step: {:.2f} ms, G_loss: {:.2f}, D_loss: {:.2f}\".format(\n",
    "            self.epoch, epoch_cost, per_step_time, mean_loss_G, mean_loss_D))\n",
    "\n",
    "        if self.epoch % self.save_checkpoint_epochs == 0:\n",
    "            save_checkpoint(net_rg_a, os.path.join(self.ckpts_dir, f\"G_A_{self.epoch}.ckpt\"))\n",
    "            save_checkpoint(net_rg_b, os.path.join(self.ckpts_dir, f\"G_B_{self.epoch}.ckpt\"))\n",
    "            save_checkpoint(net_d_a, os.path.join(self.ckpts_dir, f\"D_A_{self.epoch}.ckpt\"))\n",
    "            save_checkpoint(net_d_b, os.path.join(self.ckpts_dir, f\"D_B_{self.epoch}.ckpt\"))\n",
    "            # left latest 20, remove outdated ckpts.\n",
    "            ckpt_files = [os.path.join(self.ckpts_dir, file) for file in os.listdir(self.ckpts_dir)]\n",
    "            ckpt_files = sorted(ckpt_files, key=os.path.getmtime)\n",
    "            if len(ckpt_files) > 20:\n",
    "                for i in range(len(ckpt_files) - 20):\n",
    "                    os.remove(ckpt_files[i])\n",
    "\n",
    "    def visualizer(self, img_A, img_B, fake_A, fake_B):\n",
    "        # print(self.step, self.random_imgs_out_steps, len(self.random_imgs_out_steps))\n",
    "        if self.save_imgs and self.step in self.random_imgs_out_steps:\n",
    "            random.seed()\n",
    "            random_id = random.randint(0, self.batch_size-1)\n",
    "            save_image(img_A, os.path.join(self.imgs_epoch_dir, f\"{self.epoch}_{self.step}_{random_id}_img_B.png\"), random_id)\n",
    "            save_image(fake_B, os.path.join(self.imgs_epoch_dir, f\"{self.epoch}_{self.step}_{random_id}_fake_B.png\"), random_id)\n",
    "\n",
    "    def start_predict(self, direction):\n",
    "        self.predict_start_time = time.time()\n",
    "        self.direction = direction\n",
    "        self.info('==========start predict %s===============', self.direction)\n",
    "\n",
    "    def end_predict(self):\n",
    "        cost = (time.time() - self.predict_start_time) * 1000\n",
    "        per_step_cost = cost / self.dataset_size\n",
    "        self.info('total {} imgs cost {:.2f} ms, per img cost {:.2f}'.format(self.dataset_size, cost, per_step_cost))\n",
    "        self.info('==========end predict %s===============\\n', self.direction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练\n",
    "\n",
    "开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Args:\n",
      "--> platform: Ascend\n",
      "--> device_id: 0\n",
      "--> device_num: 1\n",
      "--> is_save_on_master: 1\n",
      "--> rank: 0\n",
      "--> group_size: 1\n",
      "--> model: ResNet\n",
      "--> init_type: normal\n",
      "--> init_gain: 0.02\n",
      "--> image_size: 256\n",
      "--> batch_size: 1\n",
      "--> pool_size: 50\n",
      "--> beta1: 0.5\n",
      "--> lr: 0.0002\n",
      "--> lr_policy: linear\n",
      "--> max_epoch: 10\n",
      "--> n_epochs: 100\n",
      "--> in_planes: 3\n",
      "--> ngf: 64\n",
      "--> gl_num: 9\n",
      "--> ndf: 64\n",
      "--> dl_num: 3\n",
      "--> slope: 0.2\n",
      "--> norm_mode: instance\n",
      "--> lambda_A: 10.0\n",
      "--> lambda_B: 10.0\n",
      "--> lambda_idt: 0.5\n",
      "--> gan_mode: lsgan\n",
      "--> pad_mode: CONSTANT\n",
      "--> dataroot: ./data/dataset/\n",
      "--> data_dir: testA\n",
      "--> outputs_dir: ./outputs\n",
      "--> load_ckpt: False\n",
      "--> G_A_ckpt: ./outputs/ckpt/G_A_200.ckpt\n",
      "--> G_B_ckpt: ./outputs/ckpt/G_B_200.ckpt\n",
      "--> D_A_ckpt: ./outputs/ckpt/D_A_200.ckpt\n",
      "--> D_B_ckpt: ./outputs/ckpt/D_B_200.ckpt\n",
      "--> save_checkpoint_epochs: 10\n",
      "--> print_iter: 100\n",
      "--> need_profiler: False\n",
      "--> save_graphs: False\n",
      "--> save_imgs: True\n",
      "--> save_img_nums: 10\n",
      "--> use_random: True\n",
      "--> need_dropout: False\n",
      "--> max_dataset_size: inf\n",
      "--> export_batch_size: 1\n",
      "--> export_file_name: CycleGAN\n",
      "--> export_file_format: MINDIR\n",
      "--> n_epochs_decay: 100\n",
      "--> phase: train\n",
      "--> dataset_size: 300\n",
      "\n",
      "==========start training===============\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:30:46.863.534 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/3499774006.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:30:46.863.628 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/3499774006.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:15.456.235 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/3499774006.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:15.456.313 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/3499774006.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:17.430.261 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2447881219.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:23.249.120 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2447881219.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.925.925 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.926.000 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.926.050 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.060 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.095 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.123 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.150 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.175 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.200 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.228 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.256 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.284 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.312 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.337 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.362 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.387 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.411 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:31.927.436 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.132.924 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.132.965 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.132.995 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.016 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.036 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.060 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.082 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.101 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:31:32.133.121 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.280.628 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.280.704 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.280.748 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.747 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.782 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.810 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.835 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.860 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.886 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.912 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.939 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.966 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.281.994 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.282.018 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.282.044 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.282.069 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.282.094 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.282.119 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.484.722 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.484.767 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.484.791 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.484.812 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.484.833 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.485.053 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.485.079 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.485.100 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:32:30.485.121 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:05.717.102 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:05.717.179 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:05.717.214 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:13.137.725 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:13.137.798 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n",
      "[ERROR] CORE(33858,ffffbab950b0,python):2024-09-09-17:33:13.137.830 [mindspore/core/utils/file_utils.cc:253] GetRealPath] Get realpath failed, path[/tmp/ipykernel_33858/2723691079.py]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1] [100/300] step cost: 1704.00 ms, G_loss: 8.69, D_loss:0.26, loss_G_A: 0.50, loss_G_B: 0.72, loss_C_A: 2.70,loss_C_B: 2.28, loss_idt_A: 1.35, loss_idt_B：1.14\n",
      "Epoch[1] [200/300] step cost: 152.48 ms, G_loss: 10.19, D_loss:0.20, loss_G_A: 0.64, loss_G_B: 0.67, loss_C_A: 2.87,loss_C_B: 3.05, loss_idt_A: 1.43, loss_idt_B：1.53\n",
      "Epoch[1] [300/300] step cost: 152.81 ms, G_loss: 12.78, D_loss:0.17, loss_G_A: 0.70, loss_G_B: 0.61, loss_C_A: 2.37,loss_C_B: 5.27, loss_idt_A: 1.19, loss_idt_B：2.64\n",
      "Epoch [1] total cost: 200939.42 ms, per step: 669.80 ms, G_loss: 9.94, D_loss: 0.25\n",
      "Epoch[2] [100/300] step cost: 152.12 ms, G_loss: 9.63, D_loss:0.22, loss_G_A: 0.72, loss_G_B: 0.31, loss_C_A: 3.24,loss_C_B: 2.49, loss_idt_A: 1.62, loss_idt_B：1.24\n",
      "Epoch[2] [200/300] step cost: 151.99 ms, G_loss: 7.01, D_loss:0.26, loss_G_A: 0.60, loss_G_B: 0.75, loss_C_A: 1.74,loss_C_B: 2.03, loss_idt_A: 0.87, loss_idt_B：1.02\n",
      "Epoch[2] [300/300] step cost: 153.33 ms, G_loss: 9.14, D_loss:0.16, loss_G_A: 0.67, loss_G_B: 0.73, loss_C_A: 3.21,loss_C_B: 1.94, loss_idt_A: 1.61, loss_idt_B：0.97\n",
      "Epoch [2] total cost: 45754.82 ms, per step: 152.52 ms, G_loss: 9.99, D_loss: 0.18\n",
      "Epoch[3] [100/300] step cost: 154.41 ms, G_loss: 10.69, D_loss:0.16, loss_G_A: 0.77, loss_G_B: 0.73, loss_C_A: 2.80,loss_C_B: 3.33, loss_idt_A: 1.40, loss_idt_B：1.66\n",
      "Epoch[3] [200/300] step cost: 151.15 ms, G_loss: 11.26, D_loss:0.21, loss_G_A: 0.71, loss_G_B: 0.81, loss_C_A: 1.74,loss_C_B: 4.76, loss_idt_A: 0.87, loss_idt_B：2.38\n",
      "Epoch[3] [300/300] step cost: 150.21 ms, G_loss: 10.93, D_loss:0.13, loss_G_A: 0.77, loss_G_B: 0.78, loss_C_A: 2.80,loss_C_B: 3.45, loss_idt_A: 1.40, loss_idt_B：1.72\n",
      "Epoch [3] total cost: 45587.45 ms, per step: 151.96 ms, G_loss: 10.05, D_loss: 0.16\n",
      "Epoch[4] [100/300] step cost: 151.33 ms, G_loss: 7.20, D_loss:0.30, loss_G_A: 0.72, loss_G_B: 0.76, loss_C_A: 1.11,loss_C_B: 2.71, loss_idt_A: 0.55, loss_idt_B：1.36\n",
      "Epoch[4] [200/300] step cost: 149.62 ms, G_loss: 9.96, D_loss:0.16, loss_G_A: 0.65, loss_G_B: 0.79, loss_C_A: 3.06,loss_C_B: 2.63, loss_idt_A: 1.53, loss_idt_B：1.31\n",
      "Epoch[4] [300/300] step cost: 150.60 ms, G_loss: 9.80, D_loss:0.14, loss_G_A: 0.68, loss_G_B: 0.72, loss_C_A: 2.62,loss_C_B: 2.98, loss_idt_A: 1.31, loss_idt_B：1.49\n",
      "Epoch [4] total cost: 45163.27 ms, per step: 150.54 ms, G_loss: 10.06, D_loss: 0.16\n",
      "Epoch[5] [100/300] step cost: 150.98 ms, G_loss: 10.05, D_loss:0.13, loss_G_A: 0.72, loss_G_B: 0.73, loss_C_A: 3.08,loss_C_B: 2.65, loss_idt_A: 1.54, loss_idt_B：1.32\n",
      "Epoch[5] [200/300] step cost: 149.86 ms, G_loss: 6.54, D_loss:0.22, loss_G_A: 0.73, loss_G_B: 0.74, loss_C_A: 2.44,loss_C_B: 0.93, loss_idt_A: 1.22, loss_idt_B：0.47\n",
      "Epoch[5] [300/300] step cost: 150.63 ms, G_loss: 8.95, D_loss:0.24, loss_G_A: 0.65, loss_G_B: 0.76, loss_C_A: 1.10,loss_C_B: 3.93, loss_idt_A: 0.55, loss_idt_B：1.97\n",
      "Epoch [5] total cost: 45153.93 ms, per step: 150.51 ms, G_loss: 10.07, D_loss: 0.16\n",
      "Epoch[6] [100/300] step cost: 150.24 ms, G_loss: 8.93, D_loss:0.19, loss_G_A: 0.66, loss_G_B: 0.79, loss_C_A: 2.66,loss_C_B: 2.33, loss_idt_A: 1.33, loss_idt_B：1.16\n",
      "Epoch[6] [200/300] step cost: 149.69 ms, G_loss: 10.59, D_loss:0.14, loss_G_A: 0.72, loss_G_B: 0.59, loss_C_A: 2.78,loss_C_B: 3.41, loss_idt_A: 1.39, loss_idt_B：1.70\n",
      "Epoch[6] [300/300] step cost: 150.31 ms, G_loss: 10.09, D_loss:0.13, loss_G_A: 0.65, loss_G_B: 0.81, loss_C_A: 3.22,loss_C_B: 2.54, loss_idt_A: 1.61, loss_idt_B：1.27\n",
      "Epoch [6] total cost: 45031.14 ms, per step: 150.10 ms, G_loss: 10.06, D_loss: 0.16\n",
      "Epoch[7] [100/300] step cost: 150.65 ms, G_loss: 9.93, D_loss:0.15, loss_G_A: 0.54, loss_G_B: 0.71, loss_C_A: 2.60,loss_C_B: 3.18, loss_idt_A: 1.30, loss_idt_B：1.59\n",
      "Epoch[7] [200/300] step cost: 149.81 ms, G_loss: 12.00, D_loss:0.13, loss_G_A: 0.79, loss_G_B: 0.74, loss_C_A: 3.04,loss_C_B: 3.94, loss_idt_A: 1.52, loss_idt_B：1.97\n",
      "Epoch[7] [300/300] step cost: 149.60 ms, G_loss: 8.14, D_loss:0.19, loss_G_A: 0.71, loss_G_B: 0.78, loss_C_A: 2.89,loss_C_B: 1.54, loss_idt_A: 1.45, loss_idt_B：0.77\n",
      "Epoch [7] total cost: 45013.57 ms, per step: 150.05 ms, G_loss: 10.03, D_loss: 0.16\n",
      "Epoch[8] [100/300] step cost: 150.94 ms, G_loss: 10.17, D_loss:0.13, loss_G_A: 0.66, loss_G_B: 0.73, loss_C_A: 2.69,loss_C_B: 3.16, loss_idt_A: 1.34, loss_idt_B：1.58\n",
      "Epoch[8] [200/300] step cost: 151.02 ms, G_loss: 10.23, D_loss:0.13, loss_G_A: 0.71, loss_G_B: 0.82, loss_C_A: 3.28,loss_C_B: 2.52, loss_idt_A: 1.64, loss_idt_B：1.26\n",
      "Epoch[8] [300/300] step cost: 151.10 ms, G_loss: 10.13, D_loss:0.14, loss_G_A: 0.78, loss_G_B: 0.75, loss_C_A: 3.24,loss_C_B: 2.50, loss_idt_A: 1.62, loss_idt_B：1.25\n",
      "Epoch [8] total cost: 45313.86 ms, per step: 151.05 ms, G_loss: 10.05, D_loss: 0.15\n",
      "Epoch[9] [100/300] step cost: 150.24 ms, G_loss: 13.96, D_loss:0.12, loss_G_A: 0.80, loss_G_B: 0.67, loss_C_A: 3.05,loss_C_B: 5.27, loss_idt_A: 1.52, loss_idt_B：2.64\n",
      "Epoch[9] [200/300] step cost: 148.98 ms, G_loss: 9.69, D_loss:0.38, loss_G_A: 0.72, loss_G_B: 0.53, loss_C_A: 2.86,loss_C_B: 2.77, loss_idt_A: 1.43, loss_idt_B：1.38\n",
      "Epoch[9] [300/300] step cost: 149.08 ms, G_loss: 10.80, D_loss:0.22, loss_G_A: 0.66, loss_G_B: 0.51, loss_C_A: 2.75,loss_C_B: 3.67, loss_idt_A: 1.37, loss_idt_B：1.84\n",
      "Epoch [9] total cost: 44836.49 ms, per step: 149.45 ms, G_loss: 69.63, D_loss: 48.57\n",
      "Epoch[10] [100/300] step cost: 149.74 ms, G_loss: 11.77, D_loss:1.06, loss_G_A: 1.19, loss_G_B: 0.55, loss_C_A: 3.30,loss_C_B: 3.38, loss_idt_A: 1.65, loss_idt_B：1.69\n",
      "Epoch[10] [200/300] step cost: 150.44 ms, G_loss: 9.82, D_loss:0.29, loss_G_A: 0.51, loss_G_B: 0.52, loss_C_A: 3.26,loss_C_B: 2.60, loss_idt_A: 1.63, loss_idt_B：1.30\n",
      "Epoch[10] [300/300] step cost: 151.24 ms, G_loss: 12.15, D_loss:0.26, loss_G_A: 0.61, loss_G_B: 0.55, loss_C_A: 3.39,loss_C_B: 3.94, loss_idt_A: 1.69, loss_idt_B：1.97\n",
      "Epoch [10] total cost: 45152.19 ms, per step: 150.51 ms, G_loss: 45.78, D_loss: 33.96\n",
      "==========end training===============\n"
     ]
    }
   ],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "\n",
    "ms.set_seed(1)\n",
    "\n",
    "def train():\n",
    "    \"\"\"Train function.\"\"\"\n",
    "    args = get_args(\"train\")\n",
    "    args.model ='ResNet' # 'DepthResNet', 'ResNet', 'UNet' \n",
    "    args.platform = 'Ascend'\n",
    "    args.max_epoch = 100\n",
    "    args.save_img_nums = 10\n",
    "    args.outputs_dir = './outputs'\n",
    "\n",
    "    if args.load_ckpt:\n",
    "        load_ckpt(args, net_rg_a, net_rg_b, net_d_a, net_d_b)\n",
    "    \n",
    "    image_pool_A = ImagePool(args.pool_size)\n",
    "    image_pool_B = ImagePool(args.pool_size)\n",
    "\n",
    "    data_loader = ds.create_dict_iterator()\n",
    "    if args.rank == 0:\n",
    "        reporter = Reporter(args)\n",
    "        reporter.info('==========start training===============')\n",
    "    \n",
    "    for _ in range(args.max_epoch):\n",
    "        if args.rank == 0:\n",
    "            reporter.epoch_start()\n",
    "        for data in data_loader:\n",
    "            img_A = data[\"image_A\"]\n",
    "            img_B = data[\"image_B\"]\n",
    "\n",
    "            res_G = train_step_g(img_A, img_B)\n",
    "            fake_A = res_G[0]\n",
    "            fake_B = res_G[1]\n",
    "            res_D = train_step_d(img_A, img_B, image_pool_A.query(fake_A), image_pool_B.query(fake_B))\n",
    "\n",
    "            if args.rank == 0:\n",
    "                reporter.step_end(res_G, res_D)\n",
    "                reporter.visualizer(img_A, img_B, fake_A, fake_B)\n",
    "        if args.rank == 0:\n",
    "            reporter.epoch_end()\n",
    "        if args.need_profiler:\n",
    "            profiler.analyse()\n",
    "            break\n",
    "    \n",
    "    if args.rank == 0:\n",
    "        reporter.info('==========end training===============')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型推理\n",
    "\n",
    "下面我们通过加载生成器网络模型参数文件来对原图进行风格迁移。\n",
    "\n",
    "推理得到的图片保存在'./outputs/predict'里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cycle GAN test.\"\"\"\n",
    "import os\n",
    "import mindspore as ms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def predict():\n",
    "    \"\"\"Predict function.\"\"\"\n",
    "    args = get_args(\"predict\")\n",
    "    args.platform = 'Ascend'\n",
    "    args.model = 'ResNet' \n",
    "    \n",
    "    ms.set_context(mode=ms.GRAPH_MODE,\n",
    "                   device_target=args.platform,\n",
    "                   save_graphs=args.save_graphs,\n",
    "                   device_id=args.device_id)\n",
    "    args.rank = 0\n",
    "    args.device_num = 1\n",
    "    if args.platform == \"GPU\":\n",
    "        ms.set_context(enable_graph_kernel=True)\n",
    "    \n",
    "    args.G_A_ckpt = './outputs/ckpt/G_A_10.ckpt'\n",
    "    args.G_B_ckpt = './outputs/ckpt/G_B_10.ckpt'\n",
    "    args.D_A_ckpt = './outputs/ckpt/D_A_10.ckpt'\n",
    "    args.D_B_ckpt = './outputs/ckpt/D_B_10.ckpt'\n",
    "\n",
    "    load_ckpt(args, net_rg_a, net_rg_b)\n",
    "\n",
    "    imgs_out = os.path.join(args.outputs_dir, \"predict\")\n",
    "    if not os.path.exists(imgs_out):\n",
    "        os.makedirs(imgs_out)\n",
    "    if not os.path.exists(os.path.join(imgs_out, \"fake_A\")):\n",
    "        os.makedirs(os.path.join(imgs_out, \"fake_A\"))\n",
    "    if not os.path.exists(os.path.join(imgs_out, \"fake_B\")):\n",
    "        os.makedirs(os.path.join(imgs_out, \"fake_B\"))\n",
    "    \n",
    "    args.data_dir = 'testA'\n",
    "    ds = create_dataset(args)\n",
    "\n",
    "    reporter = Reporter(args)\n",
    "    reporter.start_predict(\"A to B\")\n",
    "\n",
    "    for data in ds.create_dict_iterator(output_numpy=True):\n",
    "        img_A = ms.Tensor(data[\"image\"])\n",
    "        path_A = data[\"image_name\"][0]\n",
    "        if isinstance(path_A, np.bytes_):\n",
    "            path_A = path_A.decode(\"UTF-8\")\n",
    "        path_B = path_A[0:-4] + \"_fake_B.png\"\n",
    "\n",
    "        fake_B = net_rg_a(img_A)\n",
    "        save_image(fake_B, os.path.join(imgs_out, \"fake_B\", path_B))\n",
    "        save_image(img_A, os.path.join(imgs_out, \"fake_B\", path_A))\n",
    "    reporter.info('save fake_B at %s', os.path.join(imgs_out, \"fake_B\",\n",
    "                                                    path_A))\n",
    "    reporter.end_predict()\n",
    "\n",
    "    args.data_dir = 'testB'\n",
    "    ds = create_dataset(args)\n",
    "\n",
    "    reporter.dataset_size = args.dataset_size\n",
    "    reporter.start_predict(\"B to A\")\n",
    "    \n",
    "    for data in ds.create_dict_iterator(output_numpy=True):\n",
    "        img_B = ms.Tensor(data[\"image\"])\n",
    "        path_B = data[\"image_name\"][0]\n",
    "        if isinstance(path_B, np.bytes_):\n",
    "            path_B = path_B.decode(\"UTF-8\")\n",
    "        path_A = path_B[0:-4] + \"_fake_A.png\"\n",
    "        fake_A = net_rg_b(img_B)\n",
    "        save_image(fake_A, os.path.join(imgs_out, \"fake_A\", path_A))\n",
    "        save_image(img_B, os.path.join(imgs_out, \"fake_A\", path_B))\n",
    "    reporter.info('save fake_A at %s', os.path.join(imgs_out, \"fake_A\",\n",
    "                                                    path_B))\n",
    "    reporter.end_predict()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型导出\n",
    "\n",
    "下面我们通过`mindspore.export`导出MINDIR文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"export file.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import mindspore as ms\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args(\"export\")\n",
    "    args.G_A_ckpt = './outputs/ckpt/G_A_10.ckpt'\n",
    "    args.G_B_ckpt = './outputs/ckpt/G_B_10.ckpt'\n",
    "    args.D_A_ckpt = './outputs/ckpt/D_A_10.ckpt'\n",
    "    args.D_B_ckpt = './outputs/ckpt/D_B_10.ckpt'\n",
    "    \n",
    "    ms.set_context(mode=ms.GRAPH_MODE, device_target=args.platform)\n",
    "    G_A = get_generator(args)\n",
    "    G_B = get_generator(args)\n",
    "    # Use BatchNorm2d with batchsize=1, affine=False, use_batch_statistics=True instead of InstanceNorm2d\n",
    "    # Use real mean and variance rather than moving_mean and moving_varance in BatchNorm2d\n",
    "    enable_batch_statistics(G_A)\n",
    "    enable_batch_statistics(G_B)\n",
    "    load_ckpt(args, G_A, G_B)\n",
    "\n",
    "    input_shp = [args.export_batch_size, 3, args.image_size, args.image_size]\n",
    "    input_array = ms.Tensor(np.random.uniform(-1.0, 1.0, size=input_shp).astype(np.float32))\n",
    "    G_A_file = f\"{args.export_file_name}_AtoB\"\n",
    "    ms.export(G_A, input_array, file_name=G_A_file, file_format=args.export_file_format)\n",
    "    G_B_file = f\"{args.export_file_name}_BtoA\"\n",
    "    ms.export(G_B, input_array, file_name=G_B_file, file_format=args.export_file_format)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
